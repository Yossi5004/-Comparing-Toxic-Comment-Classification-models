# Comparing-Toxic-Comment-Classification-models

In this work, I present a comparison of four deep-learning techniques: One Shot, Zero Shot, Few Shot and Fine Tuning, to identify toxic comments from Internet discussions. 
My main goal is to show the performance of each technique with Transformer models.
For Zero, One and Few shot learning I used GPT-3, T5 and BART models, and for fine-tuning I used GPT-2 model. Experiments were performed on the dataset from Wikipedia (Jigsawâ€™s dataset) Toxic Comment, and the results were compared to the BERT fine-tuning model from paper [6].

# Files
1. Jupiter notebook.
2. PDF report.
